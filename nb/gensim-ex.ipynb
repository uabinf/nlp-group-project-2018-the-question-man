{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the example from https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary as D\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "document = \"This is some document...\"\n",
    "\n",
    "# load id->word mapping (the dictionary)\n",
    "id2word = D.load_from_text('wiki_en_wordids.txt')\n",
    "\n",
    "# load corpus iterator\n",
    "mm = MmCorpus('wiki_en_tfidf.mm')\n",
    "\n",
    "# extract 100 LDA topics, updating once every 10,000\n",
    "lda = LdaModel(corpus=mm, id2word=id2word, num_topics=100, update_every=1, chunksize=10000, passes=1)\n",
    "\n",
    "# use LDA model: transform new doc to bag-of-words, then apply lda\n",
    "doc_bow = D.doc2bow(document.split())\n",
    "doc_lda = lda[doc_bow]\n",
    "\n",
    "# doc_lda is vector of length num_topics representing weighted presence of each topic in the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__(\"gensim.corpora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from gensim import corpora, models, similarities\n",
    ">>>\n",
    ">>> corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    ">>>           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    ">>>           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
    ">>>           [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
    ">>>           [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
    ">>>           [(9, 1.0)],\n",
    ">>>           [(9, 1.0), (10, 1.0)],\n",
    ">>>           [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
    ">>>           [(8, 1.0), (10, 1.0), (11, 1.0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> vec = [(0, 1), (4, 1)]\n",
    ">>> print(tfidf[vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> sims = index[tfidf[vec]]\n",
    ">>> print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf[[(0, 2), (1, 2)], [(0, 2), (3, 2)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1\n",
    "\n",
    "https://radimrehurek.com/gensim/tut1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
    ">>>              \"A survey of user opinion of computer system response time\",\n",
    ">>>              \"The EPS user interface management system\",\n",
    ">>>              \"System and human system engineering testing of EPS\",\n",
    ">>>              \"Relation of user perceived response time to error measurement\",\n",
    ">>>              \"The generation of random binary unordered trees\",\n",
    ">>>              \"The intersection graph of paths in trees\",\n",
    ">>>              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    ">>>              \"Graph minors A survey\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # remove common words and tokenize\n",
    ">>> stoplist = set('for a of the and to in'.split())\n",
    ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    ">>>          for document in documents]\n",
    ">>>\n",
    ">>> # remove words that appear only once\n",
    ">>> from collections import defaultdict\n",
    ">>> frequency = defaultdict(int)\n",
    ">>> for text in texts:\n",
    ">>>     for token in text:\n",
    ">>>         frequency[token] += 1\n",
    ">>>\n",
    ">>> texts = [[token for token in text if frequency[token] > 1]\n",
    ">>>          for text in texts]\n",
    ">>>\n",
    ">>> from pprint import pprint  # pretty-printer\n",
    ">>> pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> dictionary = corpora.Dictionary(texts)\n",
    ">>> dictionary.save('deerwester.dict')\n",
    ">>> print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> corpus = [dictionary.doc2bow(text) for text in texts]\n",
    ">>> corpora.MmCorpus.serialize('deerwester.mm', corpus)\n",
    ">>> print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick insight into dealing with corpus.\n",
    "\n",
    "We need to convert our documents to text streams of a single line for easy iteratation.  This could be from pdftotext or the python web crawler\n",
    "\n",
    "a question is how do we build a dictionary that could grow over time.  if i add new documents with unknown words how do they comparer to earlier documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: transformers\n",
    "\n",
    "https://radimrehurek.com/gensim/tut2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from gensim import corpora, models, similarities\n",
    ">>> if (os.path.exists(\"deerwester.dict\")):\n",
    ">>>    dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    ">>>    corpus = corpora.MmCorpus('deerwester.mm')\n",
    ">>>    print(\"Used files generated from first tutorial\")\n",
    ">>> else:\n",
    ">>>    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> corpus_tfidf = tfidf[corpus]\n",
    ">>> for doc in corpus_tfidf:\n",
    "...     print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
    ">>> corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "...     print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 3: similarity queries\n",
    "\n",
    "https://radimrehurek.com/gensim/tut3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from gensim import corpora, models, similarities\n",
    ">>> if (os.path.exists(\"deerwester.dict\")):\n",
    ">>>    dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    ">>>    corpus = corpora.MmCorpus('deerwester.mm')\n",
    ">>>    print(\"Used files generated from first tutorial\")\n",
    ">>> else:\n",
    ">>>    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> doc = \"Human computer interaction\"\n",
    ">>> vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    ">>> vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    ">>> print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> index = similarities.MatrixSimilarity(lsi[corpus]) # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> index.save('deerwester.index')\n",
    ">>> index = similarities.MatrixSimilarity.load('deerwester.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    ">>> print(list(enumerate(sims))) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    ">>> print(sims) # print sorted (document number, similarity score) 2-tuples"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
